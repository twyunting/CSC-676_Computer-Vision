{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","provenance":[],"authorship_tag":"ABX9TyM6LBxrrirN03gdLEOg2LWa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4j6-LHgHN6RF","executionInfo":{"status":"ok","timestamp":1618082254887,"user_tz":240,"elapsed":361,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"1a64a4f1-e7aa-402d-c714-fc0fb2854d5c"},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cZOJOfQtMmJm","executionInfo":{"status":"ok","timestamp":1618082261757,"user_tz":240,"elapsed":3504,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"63a0358b-66c8-4643-caa6-05d15ea98df4"},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","import timeit\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  print(\n","      '\\n\\nThis error most likely means that this notebook is not '\n","      'configured to use a GPU.  Change this in Notebook Settings via the '\n","      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n","  raise SystemError('GPU device not found')\n","\n","def cpu():\n","  with tf.device('/cpu:0'):\n","    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n","    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n","    return tf.math.reduce_sum(net_cpu)\n","\n","def gpu():\n","  with tf.device('/device:GPU:0'):\n","    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n","    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n","    return tf.math.reduce_sum(net_gpu)\n","  \n","# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n","cpu()\n","gpu()\n","\n","# Run the op several times.\n","print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n","      '(batch x height x width x channel). Sum of ten runs.')\n","print('CPU (s):')\n","cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n","print(cpu_time)\n","print('GPU (s):')\n","gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n","print(gpu_time)\n","print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n","CPU (s):\n","2.845069413999994\n","GPU (s):\n","0.03992362099998559\n","GPU speedup over CPU: 71x\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vgs2X4JfOjsE"},"source":["# Using TensorBoard with PyTorch\n","!pip install torch torchvision\n","# !conda install pytorch torchvision -c pytorch \n","!pip install tensorboard\n","!tensorboard --logdir=runs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yh7DoFXzJYxy"},"source":["import os\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","import torchvision.utils as vutils\n","from tensorboardX import SummaryWriter\n","from data.data import InpaintingDataset, ToTensor\n","from model.net import InpaintingModel_DFBM\n","from options.train_options import TrainOptions\n","from util.utils import getLatest\n","from multiprocessing import freeze_support\n","\n","if __name__ == '__main__':\n","    config = TrainOptions().parse()\n","\n","    print('loading data..')\n","    dataset = InpaintingDataset(config.data_file,config.dataset_path , transform=transforms.Compose([\n","        ToTensor()\n","        ]))\n","    dataloader = DataLoader(dataset, batch_size=config.batch_size, shuffle=True, num_workers=4, drop_last=True)\n","\n","    print('data loaded..')\n","\n","    print('configuring model..')\n","    ourModel = InpaintingModel_DFBM(opt=config)\n","    ourModel.print_networks()\n","    if config.load_model_dir != '':\n","        print('Loading pretrained model from {}'.format(config.load_model_dir))\n","        ourModel.load_networks(getLatest(os.path.join(config.load_model_dir, '*.pth')))\n","        print('Loading done.')\n","    # ourModel = torch.nn.DataParallel(ourModel).cuda()\n","    print('model setting up..')\n","    print('training initializing..')\n","    writer = SummaryWriter(log_dir=config.model_folder)\n","    cnt = 0\n","\n","    for epoch in range(config.epochs):\n","        freeze_support()\n","        for i, data in enumerate(dataloader):\n","            gt = data['gt'].cuda()\n","            # normalize to values between -1 and 1\n","            gt = gt / 127.5 - 1\n","\n","            data_in = {'gt': gt}\n","            ourModel.setInput(data_in)\n","            ourModel.optimize_parameters()\n","            ourModel.update_learning_rate()\n","\n","            if (i + 1) % config.viz_steps == 0:\n","                ret_loss = ourModel.get_current_losses()\n","                if config.pretrain_network is False:\n","                    print(\n","                        '[%d, %5d] G_loss: %.4f (vgg: %.4f, ae: %.4f, adv: %.4f, fm_dis: %.4f, vgg_align: %.2f, '\n","                        'vgg_fm: %.2f, vgg_guided: %.2f ), D_loss: %.4f, LR : %f'\n","                        % (epoch + 1, i + 1, ret_loss['G_loss'], ret_loss['G_loss_vgg'], ret_loss['G_loss_ae'],\n","                           ret_loss['G_loss_adv'], ret_loss['G_loss_fm_dis'], ret_loss['G_loss_vgg_align'],\n","                           ret_loss['G_loss_vgg_fm'], ret_loss['G_loss_vgg_guided'], ret_loss['D_loss'],ourModel.get_current_learning_rate()))\n","                    writer.add_scalar('adv_loss', ret_loss['G_loss_adv'], cnt)\n","                    writer.add_scalar('D_loss', ret_loss['D_loss'], cnt)\n","                    writer.add_scalar('vgg_loss', ret_loss['G_loss_vgg'], cnt)\n","                    writer.add_scalar('vgg_align', ret_loss['G_loss_vgg_align'], cnt)\n","                else:\n","                    print('[%d, %5d] G_loss: %.4f (rec: %.4f, ae: %.4f)'\n","                          % (epoch + 1, i + 1, ret_loss['G_loss'], ret_loss['G_loss_rec'], ret_loss['G_loss_ae']))\n","\n","                writer.add_scalar('G_loss', ret_loss['G_loss'], cnt)\n","                writer.add_scalar('mae_loss', ret_loss['G_loss_ae'], cnt)\n","\n","                images = ourModel.get_current_visuals_tensor()\n","                im_completed = vutils.make_grid(images['completed'], normalize=True, scale_each=True)\n","                im_input = vutils.make_grid(images['input'], normalize=True, scale_each=True)\n","                im_gt = vutils.make_grid(images['gt'], normalize=True, scale_each=True)\n","                writer.add_image('gt', im_gt, cnt)\n","                writer.add_image('input', im_input, cnt)\n","                writer.add_image('completed', im_completed, cnt)\n","                if (i + 1) % config.train_spe == 0:\n","                    print('saving model ..')\n","                    ourModel.save_networks(epoch + 1)\n","            cnt += 1\n","        ourModel.save_networks(epoch + 1)\n","\n","    writer.export_scalars_to_json(os.path.join(config.model_folder, 'GMCNN_scalars.json'))\n","    writer.close()\n"],"execution_count":null,"outputs":[]}]}