{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BasicVideo.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"_oK9cYOZFQQD","colab":{"base_uri":"https://localhost:8080/","height":131},"executionInfo":{"status":"error","timestamp":1614982543898,"user_tz":300,"elapsed":442,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"a8287ff3-4ae7-4fc8-e87b-e1c290b56f5b"},"source":[" Temporal processing "],"execution_count":1,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-e444072f8ff3>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    Temporal processing\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"IazqT6pfFSMp","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"error","timestamp":1614982550857,"user_tz":300,"elapsed":289,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"89e37061-fea7-485e-fbb5-cfb0b45ef42f"},"source":["import numpy as np\n","import cv2\n","\n","cap = cv2.VideoCapture('bill.avi')\n","\n","# list of video frames\n","frames = []\n","\n","while(cap.isOpened()):\n","    # read frame from the video\n","    ret, frame = cap.read()\n","    \n","    if ret is False:\n","        break\n","        \n","    frames.append(frame)\n","\n","cap.release()\n","\n","# scale frame to 0-1\n","frames = np.array(frames) / 255.\n","print(\"frames size:\", frames.shape, \"# (nb_frames, height, width, channel)\")\n","\n","# get height, width\n","numFrames = frames.shape[0]\n","height = frames.shape[1]\n","width = frames.shape[2]"],"execution_count":3,"outputs":[{"output_type":"stream","text":["frames size: (0,) # (nb_frames, height, width, channel)\n"],"name":"stdout"},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-000232859ad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# get height, width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mnumFrames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: tuple index out of range"]}]},{"cell_type":"markdown","metadata":{"id":"0AdrnF6qFT6V"},"source":["Exerciose 1: display space-time slice of the video. Slide 22. \n","\n","Import a short video, and create a 2D plot where Y axis is t and X-axis is n, which is the horizontal cross secxtion of the movie. See lecture 11, Slide 22. \n","Hint: at each frame, take a vector of pixels at a fixed y-position and show an image of nFrames*nhorizontal pixels as a final image. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"bVgRF_ifFVi8"},"source":["Exercise 2: Create a space-temporal Gaussian filter. See Slide 28. \n","Gaussian temporal filtering (applied on a sequence of images) will blur the sequence evolution, smoothing out the temporal variation, like a rapid variation in illumination or movement of an object. It's a gaussian filtering of the signal obtained by the temporal evolution of each single pixel."]},{"cell_type":"markdown","metadata":{"id":"iO0jpW0AFZfq"},"source":["Exercise 2: Create a space-temporal Gaussian filter. See Slide 28. \n","Gaussian temporal filtering (applied on a sequence of images) will blur the sequence evolution, smoothing out the temporal variation, like a rapid variation in illumination or movement of an object. It's a gaussian filtering of the signal obtained by the temporal evolution of each single pixel."]}]}