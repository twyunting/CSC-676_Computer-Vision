{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Homework4_YuntingChiu.ipynb","provenance":[{"file_id":"1GF3vRh1DmPy3_DU8Qa4GZM6X2EN0NU9-","timestamp":1616445456809}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6lBGK_d2ItPp"},"source":["Question 1 (20pts): Basic Video Processing. You can see the tutorials on video processing:\n","https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n"]},{"cell_type":"code","metadata":{"id":"_V8mnfqC3mOd","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":37},"outputId":"05e640c3-4a8a-4d7c-bf00-dafe4c01a65f"},"source":["from google.colab import files\n","upload = files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-e9dbdaf6-d051-481f-b0aa-2b93b1624a2d\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-e9dbdaf6-d051-481f-b0aa-2b93b1624a2d\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"IazqT6pfFSMp"},"source":["%matplotlib inline\n","import numpy as np\n","from numpy.fft import fft2, ifft2, fftshift, ifftshift\n","from numpy import angle, real\n","from numpy import exp, abs, pi, sqrt\n","import matplotlib.pyplot as plt\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import imageio\n","\n","cap = cv2.VideoCapture('bill.avi')\n","\n","\n","# you can also read ay other viddos. \n","\n","# list of video frames\n","frames = []\n","\n","while(cap.isOpened()):\n","    # read frame from the video\n","    ret, frame = cap.read()\n","    \n","    if ret is False:\n","        break\n","        \n","    frames.append(frame)\n","\n","cap.release()\n","\n","# scale frame to 0-1\n","frames = np.array(frames) / 255.\n","print(\"frames size:\", frames.shape, \"# (nb_frames, height, width, channel)\")\n","\n","# get height, width\n","numFrames = frames.shape[0]\n","height = frames.shape[1]\n","width = frames.shape[2]\n","# print(frames, numFrames, height, width)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0AdrnF6qFT6V"},"source":["Question  1a : display space-time slice of the video. Figure 1.1 in the chapter. \n","\n","Import a short video, and create a 2D plot where Y axis is $t$ and X-axis is $n$, which is the **horizontal** cross secxtion of the movie. See lecture 11, Slide 22. \n","Hint: at each frame, take a vector of pixels at a fixed y-position and show an image of nFrames*nhorizontal pixels as a final image. \n","\n","References:\n","- https://stackoverflow.com/questions/65827830/disabledfunctionerror-cv2-imshow-is-disabled-in-colab-because-it-causes-jupy\n","- https://stackoverflow.com/questions/28962502/python-2-7-and-opencv-code-gives-cvtcolor-error\n","- https://docs.opencv.org/master/dd/d43/tutorial_py_video_display.html\n","- https://stackoverflow.com/questions/61775424/flipped-video-capture-and-display-in-mac-webcam-with-opencv-and-pycharm\n","\n"]},{"cell_type":"code","metadata":{"id":"znVnf3EMYrNo"},"source":["finalFrameLst=[]\n","for i in range(height):\n","  tmpList=[]\n","  for j in range(numFrames):\n","    tmp_frame = frames[j]\n","    sliceFrame = np.array([])\n","    sliceFrame = tmp_frame[i,:,:]\n","    tmpList.append(sliceFrame)\n","  finalFrameLst.append(tmpList)\n","finalFrameLst = np.array(finalFrameLst)\n","\n","print(len(finalFrameLst))\n","print(finalFrameLst[0].shape)\n","print(type(finalFrameLst[0]))\n","print(finalFrameLst[0].shape)\n","# cap.release()\n","plt.imshow(finalFrameLst[25]) # random select the 25th\n","plt.xlabel(\"n\"); plt.ylabel(\"t\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lKYeU2s1W2JL"},"source":["\"\"\"\n","import numpy as np\n","import cv2\n","\n","cap = cv2.VideoCapture('Yunting.avi')\n","\n","while (cap.isOpened()):\n","  ret, frame = cap.read()\n","\n","  # if frame is successfully read is True\n","  if not ret:\n","    print(\"Can't receive frame (stream end?). Exiting ...\")\n","    break\n","\n","  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","  cv2_imshow(gray)\n","  if cv2.waitKey(1) & 0xFF == ord('q'):\n","    break\n","\n","# When everything done, release the capture\n","cap.release()\n","cv2.destroyAllWindows()\n","print(type(gray))\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bVgRF_ifFVi8"},"source":["Question 1b: Create a space-temporal Gaussian filter. Figure 1.3 in the cvBookTemporal.pdf. See Slide 28. \n","Gaussian temporal filtering (applied on a sequence of images) will blur the sequence evolution, smoothing out the temporal variation, like a rapid variation in illumination or movement of an object. It's a gaussian filtering of the signal obtained by the temporal evolution of each single pixel."]},{"cell_type":"code","metadata":{"id":"TGBlLRffEsBn"},"source":["# generating synthetic spatio-temporal data with Gaussian process\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q0Q9_RwIJF7K"},"source":["Question 2: Motion Magnification."]},{"cell_type":"markdown","metadata":{"id":"5sZ8W5xKJWqS"},"source":["Question 2a.\n"]},{"cell_type":"code","metadata":{"id":"rPJYeqXcJzg0"},"source":["def imshow(im, cmap='gray'):\n","    # clip image from 0-1\n","    im = np.clip(im, 0, 1)\n","    plt.imshow(im, cmap=cmap)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OH_COFjwJ0tU"},"source":["# 9x9 images\n","imSize = 9\n","\n","# we would like to magnify the change between im1 and im2 by 4x\n","magnificationFactor = 4;\n","\n","# horizontal movement from (0, 0) to (0, 1)\n","im1 = np.zeros([imSize, imSize])\n","im2 = np.zeros([imSize, imSize])\n","im1[0,0] = 1\n","im2[0,1] = 1\n","\n","ff1 = fftshift(fft2(im1))\n","ff2 = fftshift(fft2(im2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dXTtMS5qKHoU"},"source":["##Magnify Change\n","\n","Firstly, we compute the prase shift between img2 to img 1 in the Fourier transform domain as `phaseShift`. Secondly, we multiply `phaseShift` by `magnificationFactor`, then add phase from img1's angle to get the final angle of the magnified image as `magnifiedDft`. Thirdly, we inverse `magnifiedDft` and keep the real part to get the magnified img as `magnified`.\n","\n","Reference: \n","- https://www.mathcentre.ac.uk/resources/sigma%20complex%20number%20leaflets/sigma-complex3-2009-1.pdf"]},{"cell_type":"code","metadata":{"id":"IscAuEUcdFSM"},"source":["print(angle(fft2(im2)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6-RnXi9KKBP"},"source":["\"\"\"\n","def pol2cart(rho, phi):\n","    x = rho * np.cos(phi)\n","    y = rho * np.sin(phi)\n","    return(x, y)\n","\"\"\"\n","\n","def magnifyChange(im1, im2, magnificationFactor):\n","    \n","    # find phase shift in frequency domain\n","    im1Dft = fft2(im1)\n","    im2Dft = fft2(im2)\n","    phaseShift = angle(im2Dft) - angle(im1Dft) # TODO\n","    \n","    # magnify the phase change in frequency domain\n","    magnifiedDft = angle(im1Dft) + magnificationFactor * phaseShift # TODO\n","    #[m,n] = pol2cart(magnifiedDft, abs(im1Dft))\n","    # what does the magnified phase change cause in image space?\n","    magnified = np.fft.ifft2(magnifiedDft).real; \n","    # magnified = ifft2(complex(m, n))\n","    \n","    return magnified"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RRGBDyVDKV6w"},"source":["HINT: If you're not familiar with complex number in python, here's a quickstart."]},{"cell_type":"code","metadata":{"id":"TQhIe5KTKa2v"},"source":["# create a complex number\n","x = 1 + 1j\n","print(\"x =\", x)\n","print(\"x.real\", x.real, \"x.imag\", x.imag)\n","\n","# magnitude and phase of complex number\n","mag = abs(x)\n","phase = angle(x) # use `angle` to see the phase\n","\n","print(\"Magnitude\", mag)\n","print(\"Phase\", phase)\n","\n","# Euler's formula\n","y = mag * exp(phase * 1j)\n","print(\"y =\", y,  y.real, y.imag)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cC1EkZlGKel7"},"source":["# magnify position change\n","magnified = magnifyChange(im1, im2, magnificationFactor);\n","\n","plt.figure(figsize=(12,36))\n","plt.subplot(131)\n","plt.imshow(im1); plt.title('im1');\n","\n","plt.subplot(132)\n","plt.imshow(im2); plt.title('im2');\n","\n","plt.subplot(133)\n","plt.imshow(magnified); plt.title('magnified');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ka_RDyAK0J8"},"source":["##Problem 3.b\n","Interpreation: "]},{"cell_type":"code","metadata":{"id":"5zvx2utcKo7Q"},"source":["# 9x9 images\n","imSize = 9\n","\n","# we would like to magnify the change between im1 and im2 by 4x\n","magnificationFactor = 4\n","\n","# horizontal movement from (0, 0) to (0, 1)\n","# additional vertical movement from (8, 8) to (7, 8)\n","im1 = np.zeros([imSize, imSize])\n","im2 = np.zeros([imSize, imSize])\n","im1[0,0] = 1\n","im2[0,1] = 1\n","im1[8,8] = 1\n","im2[7,8] = 1\n","\n","# magnify position change\n","magnified = magnifyChange(im1, im2, magnificationFactor)\n","\n","\n","plt.figure(figsize=(12,36))\n","plt.subplot(131)\n","plt.imshow(im1); plt.title('im1');\n","\n","plt.subplot(132)\n","plt.imshow(im2); plt.title('im2');\n","\n","plt.subplot(133)\n","plt.imshow(magnified); plt.title('magnified');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5oZgcEcsLB3e"},"source":["##Problem 3.c\n","\n","Reference:\n","- https://homepages.inf.ed.ac.uk/rbf/HIPR2/gsmooth.htm"]},{"cell_type":"code","metadata":{"id":"J3GRVesPLIIR"},"source":["# 9x9 images\n","imSize = 9\n","\n","# we would like to magnify the change between im1 and im2 by 4x\n","magnificationFactor = 4\n","\n","# width of our Gaussian window\n","sigma = 2\n","\n","# horizontal movement from (0, 0) to (0, 1)\n","# additional vertical movement from (8, 8) to (7, 8)\n","im1 = np.zeros([imSize, imSize])\n","im2 = np.zeros([imSize, imSize])\n","im1[0,0] = 1\n","im2[0,1] = 1\n","im1[8,8] = 1\n","im2[7,8] = 1\n","\n","# we will magnify windows of the image and aggregate the results\n","magnified = np.zeros([imSize, imSize])\n","\n","# meshgrid for computing Gaussian window\n","X, Y = np.meshgrid(np.arange(imSize), np.arange(imSize))\n","# print(X)\n","\n","for y in range(0, imSize, 2*sigma):\n","  for x in range(0, imSize, 2*sigma):\n","    gaussianMask = np.exp((-(X-x)^2 - (Y-y)^2)/ (2 * sigma ^2 )) # TODO\n","    IM1, IM2 = im1*gaussianMask, im2*gaussianMask # TODO\n","    windowMagnified = magnifyChange(IM1, IM2, magnificationFactor) # TODO\n","    magnified = magnified + windowMagnified\n","        \n","plt.figure(figsize=(12,36))\n","plt.subplot(131)\n","imshow(im1); plt.title('im1');\n","\n","plt.subplot(132)\n","imshow(im2); plt.title('im2');\n","\n","plt.subplot(133)\n","imshow(magnified); plt.title('magnified');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5nnckH0HLN7r"},"source":["##Problem 3.d"]},{"cell_type":"code","metadata":{"id":"wOzehF6ELRiL"},"source":["import numpy as np\n","import cv2\n","\n","cap = cv2.VideoCapture('bill.avi')\n","\n","# list of video frames\n","frames = []\n","\n","while(cap.isOpened()):\n","    # read frame from the video\n","    ret, frame = cap.read()\n","    \n","    if ret is False:\n","        break\n","        \n","    frames.append(frame)\n","\n","cap.release()\n","\n","# scale frame to 0-1\n","frames = np.array(frames) / 255.\n","print(\"frames size:\", frames.shape, \"# (nb_frames, height, width, channel)\")\n","\n","# get height, width\n","numFrames = frames.shape[0]\n","height = frames.shape[1]\n","width = frames.shape[2]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TGnmtwmILVU5"},"source":["##Motion magnification\n","Fill out code here marked with #TODO"]},{"cell_type":"code","metadata":{"id":"Xqg3D1PU1wDu"},"source":["# 10x magnification of motion\n","magnificationFactor = 10\n","\n","# width of Gaussian window\n","sigma = 13\n","\n","# alpha for moving average\n","alpha = 0.5\n","\n","# we will magnify windows of the video and aggregate the results\n","magnified = np.zeros_like(frames)\n","\n","# meshgrid for computing Gaussian window\n","X, Y = np.meshgrid(np.arange(width), np.arange(height))\n","\n","# iterate over windows of the frames\n","xRange = list(range(0, width, 2*sigma))\n","yRange = list(range(0, height, 2*sigma))\n","numWindows = len(xRange) * len(yRange)\n","windowIndex = 1\n","\n","for y in yRange:\n","    for x in xRange:\n","        for channelIndex in range(3): # RGB channels\n","            for frameIndex in range(numFrames):\n","                \n","                # create windowed frames\n","                gaussianMask = np.exp(-((X-x)^2 + (Y-y)^2) / (2 * sigma^2)) # TODO\n","                windowedFrames = gaussianMask * frames[frameIndex,:,:,channelIndex]\n","            \n","                # initialize moving average of phase for current window/channel\n","                if frameIndex == 0:\n","                    windowAveragePhase = angle(fft2(windowedFrames))\n","                \n","                windowDft = fft2(windowedFrames)\n","                \n","                # compute phase shift and constrain to [-pi, pi] since\n","                # angle space wraps around\n","                windowPhaseShift = angle(windowDft) - windowAveragePhase\n","                windowPhaseShift[windowPhaseShift > pi] = windowPhaseShift[windowPhaseShift > pi] - 2 * pi\n","                windowPhaseShift[windowPhaseShift < -pi] = windowPhaseShift[windowPhaseShift < -pi] + 2 * pi\n","                \n","                # magnify phase shift\n","                windowMagnifiedPhase = windowAveragePhase + windowPhaseShift * magnificationFactor # TODO\n","                 \n","                # go back to image space\n","                windowMagnifiedDft = np.fft.ifft2(windowMagnifiedPhase) # TODO\n","                windowMagnified = abs(ifft2(windowMagnifiedDft))\n","                \n","                # update moving average\n","                windowPhaseUnwrapped = windowAveragePhase + windowPhaseShift\n","                windowAveragePhase = alpha * windowAveragePhase + (1 - alpha) * windowPhaseUnwrapped\n","                \n","                # aggregate\n","                magnified[frameIndex,:,:,channelIndex] = magnified[frameIndex,:,:,channelIndex] + windowMagnified\n","        \n","        # print progress\n","        print('{}/{}'.format(windowIndex, numWindows), end='\\r')\n","        windowIndex += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRVWCba72B7I"},"source":["outputs = magnified / np.max(magnified)\n","for channelIndex in range(3):\n","    originalFrame = frames[0,:,:,channelIndex]\n","    magnifiedFrame = outputs[0,:,:,channelIndex]\n","    scale = np.std(originalFrame[:]) / np.std(magnifiedFrame[:])\n","    originalMean = np.mean(originalFrame[:])\n","    magnifiedMean = np.mean(magnifiedFrame[:])\n","    outputs[:,:,:,channelIndex] = magnifiedMean + scale * (outputs[:,:,:,channelIndex] - magnifiedMean)\n","\n","outputs = np.clip(outputs, 0, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oWGoygcI2C_5"},"source":["# create output video\n","fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n","# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","out = cv2.VideoWriter('bill_magnified.avi',fourcc, 30.0, (height, width))\n","\n","for i in range(frames.shape[0]):\n","    # scale the frame back to 0-255\n","    frame = (np.clip(outputs[i], 0, 1) * 255).astype(np.uint8)\n","    \n","    # write frame to output video\n","    out.write(frame)\n","\n","out.release()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wNRa3c52E-Z"},"source":["# Only for colab downloading videos\n","try:\n","    from google.colab import files\n","    files.download('bill_magnified.avi')\n","except:\n","    print(\"Only for google colab\")"],"execution_count":null,"outputs":[]}]}