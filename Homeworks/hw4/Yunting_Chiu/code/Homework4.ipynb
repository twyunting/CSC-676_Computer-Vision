{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Homework4.ipynb","provenance":[{"file_id":"1GF3vRh1DmPy3_DU8Qa4GZM6X2EN0NU9-","timestamp":1616445456809}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6lBGK_d2ItPp"},"source":["Question 1 (20pts): Basic Video Processing. You can see the tutorials on video processing:\n","https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n"]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":72},"id":"_V8mnfqC3mOd","executionInfo":{"status":"ok","timestamp":1616596110824,"user_tz":240,"elapsed":29933,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"15f811e5-32ab-4940-b5a0-e4944913851d"},"source":["from google.colab import files\n","upload = files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-99d06fe9-3f0c-453a-9006-fe7c77561f01\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-99d06fe9-3f0c-453a-9006-fe7c77561f01\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving bill.avi to bill.avi\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IazqT6pfFSMp","colab":{"base_uri":"https://localhost:8080/","height":252},"executionInfo":{"status":"error","timestamp":1616622802762,"user_tz":240,"elapsed":900,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"03475aef-5c12-4177-d80a-34fcea40984d"},"source":["%matplotlib inline\n","import numpy as np\n","from numpy.fft import fft2, ifft2, fftshift, ifftshift\n","from numpy import angle, real\n","from numpy import exp, abs, pi, sqrt\n","import matplotlib.pyplot as plt\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import imageio\n","\n","cap = cv2.VideoCapture('bill.avi')\n","\n","\n","# you can also read ay other viddos. \n","\n","# list of video frames\n","frames = []\n","\n","while(cap.isOpened()):\n","    # read frame from the video\n","    ret, frame = cap.read()\n","    \n","    if ret is False:\n","        break\n","        \n","    frames.append(frame)\n","\n","cap.release()\n","\n","# scale frame to 0-1\n","frames = np.array(frames) / 255.\n","print(\"frames size:\", frames.shape, \"# (nb_frames, height, width, channel)\")\n","\n","# get height, width\n","numFrames = frames.shape[0]\n","height = frames.shape[1]\n","width = frames.shape[2]\n","print(numFrames, height, width)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["frames size: (0,) # (nb_frames, height, width, channel)\n"],"name":"stdout"},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-86bb904cfb8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# get height, width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mnumFrames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumFrames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: tuple index out of range"]}]},{"cell_type":"markdown","metadata":{"id":"0AdrnF6qFT6V"},"source":["Question  1a : display space-time slice of the video. Figure 1.1 in the chapter. \n","\n","Import a short video, and create a 2D plot where Y axis is $t$ and X-axis is $n$, which is the **horizontal** cross secxtion of the movie. See lecture 11, Slide 22. \n","Hint: at each frame, take a vector of pixels at a fixed y-position and show an image of nFrames*nhorizontal pixels as a final image. \n","\n","References:\n","- https://stackoverflow.com/questions/65827830/disabledfunctionerror-cv2-imshow-is-disabled-in-colab-because-it-causes-jupy\n","- https://stackoverflow.com/questions/28962502/python-2-7-and-opencv-code-gives-cvtcolor-error\n","- https://docs.opencv.org/master/dd/d43/tutorial_py_video_display.html\n","\n"]},{"cell_type":"code","metadata":{"id":"lKYeU2s1W2JL"},"source":["import numpy as np\n","import cv2\n","\n","cap = cv2.VideoCapture('bill.avi')\n","\n","while (cap.isOpened()):\n","  ret, frame = cap.read()\n","\n","  # if frame is successfully read is True\n","  if not ret:\n","    print(\"Can't receive frame (stream end?). Exiting ...\")\n","    break\n","\n","  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","  cv2_imshow(gray)\n","  if cv2.waitKey(1) & 0xFF == ord('q'):\n","    break\n","\n","# When everything done, release the capture\n","cap.release()\n","cv2.destroyAllWindows()\n","print(type(gray))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bVgRF_ifFVi8"},"source":["Question 1b: Create a space-temporal Gaussian filter. Figure 1.3 in the cvBookTemporal.pdf. See Slide 28. \n","Gaussian temporal filtering (applied on a sequence of images) will blur the sequence evolution, smoothing out the temporal variation, like a rapid variation in illumination or movement of an object. It's a gaussian filtering of the signal obtained by the temporal evolution of each single pixel."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131},"id":"TGBlLRffEsBn","executionInfo":{"status":"error","timestamp":1616623105068,"user_tz":240,"elapsed":201,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"398414d7-667e-423d-e954-bd3ed6a4c019"},"source":["gaussianMask = exp((-(X-x).^2 - (Y- y).^2)/ (2 * sigma ^2 ))\n","im11 = im1.*gaussianMask;\n","im22 = im2.*gaussianMask;\n","windowMagnified = magnifyChange(im11, im22, magnificationFactor)\n","magnified = magnified + windowMagnified;"],"execution_count":6,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-af15b805e7c0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    gaussianMask = exp((-(X-x).^2 - (Y- y).^2)/ (2 * sigma ^2 ))\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"markdown","metadata":{"id":"Q0Q9_RwIJF7K"},"source":["Question 2: Motion Manificaton."]},{"cell_type":"markdown","metadata":{"id":"5sZ8W5xKJWqS"},"source":["Question 2a.\n"]},{"cell_type":"code","metadata":{"id":"rPJYeqXcJzg0","executionInfo":{"status":"ok","timestamp":1616622053467,"user_tz":240,"elapsed":485,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}}},"source":["def imshow(im, cmap='gray'):\n","    # clip image from 0-1\n","    im = np.clip(im, 0, 1)\n","    plt.imshow(im, cmap=cmap)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"OH_COFjwJ0tU","executionInfo":{"status":"ok","timestamp":1616622806360,"user_tz":240,"elapsed":178,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}}},"source":["# 9x9 images\n","imSize = 9\n","\n","# we would like to magnify the change between im1 and im2 by 4x\n","magnificationFactor = 4;\n","\n","# horizontal movement from (0, 0) to (0, 1)\n","im1 = np.zeros([imSize, imSize])\n","im2 = np.zeros([imSize, imSize])\n","im1[0,0] = 1\n","im2[0,1] = 1\n","\n","ff1 = fftshift(fft2(im1))\n","ff2 = fftshift(fft2(im2))"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dXTtMS5qKHoU"},"source":["##Magnify Change\n","Fill out code here"]},{"cell_type":"code","metadata":{"id":"Q6-RnXi9KKBP","colab":{"base_uri":"https://localhost:8080/","height":131},"executionInfo":{"status":"error","timestamp":1616596111814,"user_tz":240,"elapsed":30896,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"ee5797ba-e744-40a1-a205-40bdca75c5ce"},"source":["def magnifyChange(im1, im2, magnificationFactor):\n","    \n","    # find phase shift in frequency domain\n","    im1Dft = fft2(im1)\n","    im2Dft = fft2(im2)\n","    phaseShift = # TODO\n","    \n","    # magnify the phase change in frequency domain\n","    magnifiedDft = # TODO\n","    \n","    # what does the magnified phase change cause in image space?\n","    magnified = ifft2(magnifiedDft).real;\n","    \n","    return magnified"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-424cf0eb493d>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    phaseShift = # TODO\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"markdown","metadata":{"id":"RRGBDyVDKV6w"},"source":["HINT: If you're not familiar with complex number in python, here's a quickstart."]},{"cell_type":"code","metadata":{"id":"TQhIe5KTKa2v"},"source":["# create a complex number\n","x = 1 + 1j\n","print(\"x =\", x)\n","print(\"x.real\", x.real, \"x.imag\", x.imag)\n","\n","# magnitude and phase of complex number\n","mag = abs(x)\n","phase = angle(x)\n","\n","print(\"Magnitude\", mag)\n","print(\"Phase\", phase)\n","\n","# Euler's formula\n","y = mag * exp(phase * 1j)\n","print(\"y =\", y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cC1EkZlGKel7"},"source":["# magnify position change\n","magnified = magnifyChange(im1, im2, magnificationFactor);\n","\n","plt.figure(figsize=(12,36))\n","plt.subplot(131)\n","imshow(im1); plt.title('im1');\n","\n","plt.subplot(132)\n","imshow(im2); plt.title('im2');\n","\n","plt.subplot(133)\n","imshow(magnified); plt.title('magnified');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ka_RDyAK0J8"},"source":["##Problem 3.b"]},{"cell_type":"code","metadata":{"id":"5zvx2utcKo7Q"},"source":["# 9x9 images\n","imSize = 9\n","\n","# we would like to magnify the change between im1 and im2 by 4x\n","magnificationFactor = 4\n","\n","# horizontal movement from (0, 0) to (0, 1)\n","# additional vertical movement from (8, 8) to (7, 8)\n","im1 = np.zeros([imSize, imSize])\n","im2 = np.zeros([imSize, imSize])\n","im1[0,0] = 1\n","im2[0,1] = 1\n","im1[8,8] = 1\n","im2[7,8] = 1\n","\n","# magnify position change\n","magnified = magnifyChange(im1, im2, magnificationFactor)\n","\n","\n","plt.figure(figsize=(12,36))\n","plt.subplot(131)\n","imshow(im1); plt.title('im1');\n","\n","plt.subplot(132)\n","imshow(im2); plt.title('im2');\n","\n","plt.subplot(133)\n","imshow(magnified); plt.title('magnified');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5oZgcEcsLB3e"},"source":["##Problem 3.c\n","Fill out code here"]},{"cell_type":"code","metadata":{"id":"J3GRVesPLIIR"},"source":["# 9x9 images\n","imSize = 9\n","\n","# we would like to magnify the change between im1 and im2 by 4x\n","magnificationFactor = 4\n","\n","# width of our Gaussian window\n","sigma = 2\n","\n","# horizontal movement from (0, 0) to (0, 1)\n","# additional vertical movement from (8, 8) to (7, 8)\n","im1 = np.zeros([imSize, imSize])\n","im2 = np.zeros([imSize, imSize])\n","im1[0,0] = 1\n","im2[0,1] = 1\n","im1[8,8] = 1\n","im2[7,8] = 1\n","\n","# we will magnify windows of the image and aggregate the results\n","magnified = np.zeros([imSize, imSize])\n","\n","# meshgrid for computing Gaussian window\n","X, Y = np.meshgrid(np.arange(imSize), np.arange(imSize))\n","\n","for y in range(0, imSize, 2*sigma):\n","    for x in range(0, imSize, 2*sigma):\n","        gaussianMask = # TODO\n","        windowMagnified = magnifyChange(# TODO,\\\n","            magnificationFactor)\n","        magnified = magnified + windowMagnified\n","        \n","plt.figure(figsize=(12,36))\n","plt.subplot(131)\n","imshow(im1); plt.title('im1');\n","\n","plt.subplot(132)\n","imshow(im2); plt.title('im2');\n","\n","plt.subplot(133)\n","imshow(magnified); plt.title('magnified');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5nnckH0HLN7r"},"source":["##Problem 3.d"]},{"cell_type":"code","metadata":{"id":"wOzehF6ELRiL"},"source":["import numpy as np\n","import cv2\n","\n","cap = cv2.VideoCapture('bill.avi')\n","\n","# list of video frames\n","frames = []\n","\n","while(cap.isOpened()):\n","    # read frame from the video\n","    ret, frame = cap.read()\n","    \n","    if ret is False:\n","        break\n","        \n","    frames.append(frame)\n","\n","cap.release()\n","\n","# scale frame to 0-1\n","frames = np.array(frames) / 255.\n","print(\"frames size:\", frames.shape, \"# (nb_frames, height, width, channel)\")\n","\n","# get height, width\n","numFrames = frames.shape[0]\n","height = frames.shape[1]\n","width = frames.shape[2]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TGnmtwmILVU5"},"source":["##Motion magnification\n","Fill out code here marked with #TODO"]},{"cell_type":"code","metadata":{"id":"Xqg3D1PU1wDu"},"source":["# 10x magnification of motion\n","magnificationFactor = 10\n","\n","# width of Gaussian window\n","sigma = 13\n","\n","# alpha for moving average\n","alpha = 0.5\n","\n","# we will magnify windows of the video and aggregate the results\n","magnified = np.zeros_like(frames)\n","\n","# meshgrid for computing Gaussian window\n","X, Y = np.meshgrid(np.arange(width), np.arange(height))\n","\n","# iterate over windows of the frames\n","xRange = list(range(0, width, 2*sigma))\n","yRange = list(range(0, height, 2*sigma))\n","numWindows = len(xRange) * len(yRange)\n","windowIndex = 1\n","\n","for y in yRange:\n","    for x in xRange:\n","        for channelIndex in range(3): # RGB channels\n","            for frameIndex in range(numFrames):\n","                \n","                # create windowed frames\n","                gaussianMask = # TODO\n","                windowedFrames = gaussianMask * frames[frameIndex,:,:,channelIndex]\n","            \n","                # initialize moving average of phase for current window/channel\n","                if frameIndex == 0:\n","                    windowAveragePhase = angle(fft2(windowedFrames))\n","                \n","                windowDft = fft2(windowedFrames)\n","                \n","                # compute phase shift and constrain to [-pi, pi] since\n","                # angle space wraps around\n","                windowPhaseShift = angle(windowDft) - windowAveragePhase\n","                windowPhaseShift[windowPhaseShift > pi] = windowPhaseShift[windowPhaseShift > pi] - 2 * pi\n","                windowPhaseShift[windowPhaseShift < -pi] = windowPhaseShift[windowPhaseShift < -pi] + 2 * pi\n","                \n","                # magnify phase shift\n","                windowMagnifiedPhase = # TODO\n","                 \n","                # go back to image space\n","                windowMagnifiedDft = # TODO\n","                windowMagnified = abs(ifft2(windowMagnifiedDft))\n","                \n","                # update moving average\n","                windowPhaseUnwrapped = windowAveragePhase + windowPhaseShift\n","                windowAveragePhase = alpha * windowAveragePhase + (1 - alpha) * windowPhaseUnwrapped\n","                \n","                # aggregate\n","                magnified[frameIndex,:,:,channelIndex] = magnified[frameIndex,:,:,channelIndex] + windowMagnified\n","        \n","        # print progress\n","        print('{}/{}'.format(windowIndex, numWindows), end='\\r')\n","        windowIndex += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRVWCba72B7I"},"source":["outputs = magnified / np.max(magnified)\n","for channelIndex in range(3):\n","    originalFrame = frames[0,:,:,channelIndex]\n","    magnifiedFrame = outputs[0,:,:,channelIndex]\n","    scale = np.std(originalFrame[:]) / np.std(magnifiedFrame[:])\n","    originalMean = np.mean(originalFrame[:])\n","    magnifiedMean = np.mean(magnifiedFrame[:])\n","    outputs[:,:,:,channelIndex] = magnifiedMean + scale * (outputs[:,:,:,channelIndex] - magnifiedMean)\n","\n","outputs = np.clip(outputs, 0, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oWGoygcI2C_5"},"source":["# create output video\n","fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n","# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","out = cv2.VideoWriter('bill_magnified.avi',fourcc, 30.0, (height, width))\n","\n","for i in range(frames.shape[0]):\n","    # scale the frame back to 0-255\n","    frame = (np.clip(outputs[i], 0, 1) * 255).astype(np.uint8)\n","    \n","    # write frame to output video\n","    out.write(frame)\n","\n","out.release()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wNRa3c52E-Z"},"source":["# Only for colab downloading videos\n","try:\n","    from google.colab import files\n","    files.download('bill_magnified.avi')\n","except:\n","    print(\"Only for google colab\")"],"execution_count":null,"outputs":[]}]}